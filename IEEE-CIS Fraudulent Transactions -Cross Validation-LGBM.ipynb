{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Test for LightGBM\n",
    "### New Cross Validation Scheme\n",
    "- Just doing cross validation on the whole test data and then averaging these to submit to the leaderboard has a few flaws:\n",
    "    - potential overfit to leaderboard since we are using that for model validation\n",
    "    - potential data leakage in each fold\n",
    "    \n",
    "- to do a proper model validation, it is good practice to have an extra holdout set to test the model predictions. If the holdout set predictions are not too different from the CV performance then we can be more confident on generalisation to new data\n",
    "- disadvantage is less data for training the model (we can't do this well if we have a small dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import datetime\n",
    "import missingno as msno\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit, train_test_split,StratifiedKFold\n",
    "import gc\n",
    "from statistics import mean\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Cross Validation\n",
    "1. Divide Train set in subsets (Cross Validation folds + Holdout set (separate from leaderboard test set))\n",
    "2. Define Validation Metric (in our case it is ROC-AUC)\n",
    "3. Stop training when Validation metric stops improving\n",
    "4. Take average of each fold's prediction for the Local Test set.\n",
    "\n",
    "* Make sure to set shuffle=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full = pd.read_pickle('data/train_full.pkl')\n",
    "test_full = pd.read_pickle('data/test_full.pkl')\n",
    "\n",
    "train_full=train_full.sort_values('TransactionDT',ascending=True).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "for f in test_full.columns:\n",
    "    if train_full[f].dtype=='object' or test_full[f].dtype=='object': \n",
    "        train_full[f] = train_full[f].fillna('unseen_before_label')\n",
    "        test_full[f]  = test_full[f].fillna('unseen_before_label')\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(train_full[f].values) + list(test_full[f].values))\n",
    "        train_full[f] = lbl.transform(list(train_full[f].values))\n",
    "        test_full[f] = lbl.transform(list(test_full[f].values)) \n",
    "        \n",
    "        \n",
    "train_full = train_full.fillna(-999)\n",
    "test_full = test_full.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_cols = [\n",
    "    'TransactionID','TransactionDT', \n",
    "    'isFraud'                         \n",
    "]\n",
    "\n",
    "# Final features\n",
    "features_columns = [col for col in list(train_full.columns) if col not in rm_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_full[features_columns]\n",
    "y = train_full['isFraud']\n",
    "\n",
    "# # Split holdout as 15% of the train set - probably don't need this as the holdout performance is very similar anyway, lets just rely on my CV and the LB\n",
    "# X, X_holdout, y, y_holdout = train_test_split(train_full[features_columns], train_full['isFraud'], \n",
    "#                                               test_size=0.15, random_state=42, shuffle=False)\n",
    "# #                                               stratify = train_full['isFraud'])\n",
    "\n",
    "del train_full\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.01, # speed up the learning rate a bit - might sacrifice a bit of accuracy\n",
    "                    'num_leaves':2**8, # reduce number of leaves to reduce overfitting\n",
    "                    'max_depth': -1, # max_depth should be constrained, -1 would mean unconstrained\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.7,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.7,\n",
    "                    'n_estimators':800,\n",
    "                    'max_bin':255, # less bins if overfitting\n",
    "                    'verbose':-1,\n",
    "                    'seed': 2019,\n",
    "                    'early_stopping_rounds':100,\n",
    "#                     'lambda_l1':5,\n",
    "#                     'lambda_l2':5,\n",
    "                } \n",
    "\n",
    "# params = {\n",
    "#                     'objective':'binary',\n",
    "#                     'boosting_type':'gbdt',\n",
    "#                     'metric':'auc',\n",
    "#                     'n_jobs':-1,\n",
    "#                     'learning_rate':0.05, # speed up the learning rate a bit - might sacrifice a bit of accuracy\n",
    "#                     'num_leaves':2**8, # reduce number of leaves to reduce overfitting\n",
    "#                     'max_depth': 8, # max_depth should be constrained, -1 would mean unconstrained\n",
    "#                     'tree_learner':'serial',\n",
    "#                     'colsample_bytree': 0.7,\n",
    "#                     'subsample_freq':1,\n",
    "#                     'subsample':0.7,\n",
    "#                     'n_estimators':1000,\n",
    "#                     'max_bin':255, # less bins if overfitting\n",
    "#                     'verbose':-1,\n",
    "#                     'seed': 2019,\n",
    "#                     'early_stopping_rounds':100,\n",
    "# #                     'lambda_l1':5,\n",
    "# #                     'lambda_l2':5,\n",
    "#                 } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\martin.cheung\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\martin.cheung\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:118: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's auc: 0.951756\tvalid_1's auc: 0.886563\n",
      "[400]\ttraining's auc: 0.979561\tvalid_1's auc: 0.904942\n",
      "[600]\ttraining's auc: 0.989616\tvalid_1's auc: 0.913059\n",
      "[800]\ttraining's auc: 0.994189\tvalid_1's auc: 0.916755\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's auc: 0.994189\tvalid_1's auc: 0.916755\n",
      "AUC for validation fold 1: 0.9167548469992037\n",
      "Training on fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's auc: 0.951624\tvalid_1's auc: 0.905164\n",
      "[400]\ttraining's auc: 0.98051\tvalid_1's auc: 0.923355\n",
      "[600]\ttraining's auc: 0.990884\tvalid_1's auc: 0.930018\n",
      "[800]\ttraining's auc: 0.995133\tvalid_1's auc: 0.933007\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's auc: 0.995133\tvalid_1's auc: 0.933007\n",
      "AUC for validation fold 2: 0.9330067559668452\n",
      "Training on fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's auc: 0.954347\tvalid_1's auc: 0.90912\n",
      "[400]\ttraining's auc: 0.981357\tvalid_1's auc: 0.92469\n",
      "[600]\ttraining's auc: 0.990991\tvalid_1's auc: 0.931152\n",
      "[800]\ttraining's auc: 0.995249\tvalid_1's auc: 0.933352\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's auc: 0.995249\tvalid_1's auc: 0.933352\n",
      "AUC for validation fold 3: 0.9333519498681416\n",
      "Training on fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's auc: 0.948852\tvalid_1's auc: 0.922821\n",
      "[400]\ttraining's auc: 0.980105\tvalid_1's auc: 0.941889\n",
      "[600]\ttraining's auc: 0.990358\tvalid_1's auc: 0.94802\n",
      "[800]\ttraining's auc: 0.994953\tvalid_1's auc: 0.950147\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's auc: 0.994953\tvalid_1's auc: 0.950147\n",
      "AUC for validation fold 4: 0.9501469047530153\n",
      "Training on fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's auc: 0.951835\tvalid_1's auc: 0.898524\n",
      "[400]\ttraining's auc: 0.980557\tvalid_1's auc: 0.917235\n",
      "[600]\ttraining's auc: 0.990622\tvalid_1's auc: 0.923287\n",
      "[800]\ttraining's auc: 0.994967\tvalid_1's auc: 0.925541\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's auc: 0.994967\tvalid_1's auc: 0.925541\n",
      "AUC for validation fold 5: 0.9255408129877762\n",
      "Cross Validation AUC:  0.9317602541149965\n"
     ]
    }
   ],
   "source": [
    "NFOLDS =5\n",
    "# folds = StratifiedKFold(n_splits=NFOLDS,random_state=123,shuffle=False) # split by stratified folds\n",
    "folds = KFold(n_splits=NFOLDS,random_state=123,shuffle=False) # split by stratified folds\n",
    "# folds = TimeSeriesSplit(n_splits=NFOLDS) # split by time - try timeseries split, perhaps less overfitting? result: worse overfitting\n",
    "\n",
    "aucs = []\n",
    "clfs=[]\n",
    "pred_len = len(test_full)\n",
    "prediction = np.zeros(pred_len)\n",
    "\n",
    "for fold, (trn_idx, test_idx) in enumerate(folds.split(X,y)):\n",
    "    print('Training on fold {}'.format(fold + 1))\n",
    "    \n",
    "    trn_data = lgb.Dataset(data=X.iloc[trn_idx], label=y.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(data=X.iloc[test_idx], label=y.iloc[test_idx])\n",
    "    clf = lgb.train(params, \n",
    "                    trn_data, \n",
    "                    valid_sets = [trn_data, val_data], \n",
    "                    verbose_eval=200)\n",
    "    \n",
    "    print('AUC for validation fold {}: {}'.format(fold+1, clf.best_score['valid_1']['auc']))\n",
    "    aucs.append(clf.best_score['valid_1']['auc'])\n",
    "    \n",
    "#     holdout_pred = clf.predict(X_holdout)\n",
    "#     print('AUC for holdout set - fold ', roc_auc_score(y_holdout, holdout_pred))\n",
    "    \n",
    "    prediction += clf.predict(test_full[features_columns])\n",
    "\n",
    "print(\"Cross Validation AUC: \", sum(aucs)/NFOLDS)\n",
    "final_predictions = prediction/NFOLDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average AUC for the timeseries split is much lower, and the LB score is a lower too. Might not be the correct CV scheme for time series as well. Still need to look for a good CV scheme.\n",
    "\n",
    "KFold Performance: CV: 0.9317; LB: 0.9417"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 20))\n",
    "lgb.plot_importance(clf,max_num_features=50,ax=ax)\n",
    "# for i in range(NFOLDS):\n",
    "#     fig, ax = plt.subplots(figsize=(15, 20))\n",
    "#     xgb.plot_importance(clfs[i],max_num_features=50,ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv', index_col='TransactionID')\n",
    "sample_submission['isFraud'] = prediction\n",
    "sample_submission.to_csv('data/lightgbm_cv_kfold_noholdout.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
