{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Cross Validation Scheme\n",
    "- Just doing cross validation on the whole test data and then averaging these to submit to the leaderboard has a few flaws:\n",
    "    - potential overfit to leaderboard since we are using that for model validation\n",
    "    - potential data leakage in each fold\n",
    "    \n",
    "- to do a proper model validation, it is good practice to have an extra holdout set to test the model predictions. If the holdout set predictions are not too different from the CV performance then we can be more confident on generalisation to new data\n",
    "- disadvantage is less data for training the model (we can't do this well if we have a small dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import datetime\n",
    "import missingno as msno\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit, train_test_split,StratifiedKFold\n",
    "import gc\n",
    "from statistics import mean\n",
    "import pickle\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Cross Validation\n",
    "1. Divide Train set in subsets (Cross Validation folds + Holdout set (separate from leaderboard test set))\n",
    "2. Define Validation Metric (in our case it is ROC-AUC)\n",
    "3. Stop training when Validation metric stops improving\n",
    "4. Take average of each fold's prediction for the Local Test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full = pd.read_pickle('data/train_feat.pkl')\n",
    "test_full = pd.read_pickle('data/test_feat.pkl')\n",
    "\n",
    "# Label Encoding for categoricals\n",
    "for f in test_full.columns:\n",
    "    if train_full[f].dtype=='object' or test_full[f].dtype=='object': \n",
    "        train_full[f] = train_full[f].fillna('unseen_before_label')\n",
    "        test_full[f]  = test_full[f].fillna('unseen_before_label')\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(train_full[f].values) + list(test_full[f].values))\n",
    "        train_full[f] = lbl.transform(list(train_full[f].values))\n",
    "        test_full[f] = lbl.transform(list(test_full[f].values)) \n",
    "\n",
    "# Fill NA's for numerics\n",
    "train_full = train_full.fillna(-999)\n",
    "test_full = test_full.fillna(-999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the 200 features chosen by the RFE feature selection previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TransactionAmt',\n",
       " 'ProductCD',\n",
       " 'card1',\n",
       " 'card2',\n",
       " 'card3',\n",
       " 'card4',\n",
       " 'card5',\n",
       " 'card6',\n",
       " 'addr1',\n",
       " 'addr2',\n",
       " 'dist1',\n",
       " 'dist2',\n",
       " 'P_emaildomain',\n",
       " 'R_emaildomain',\n",
       " 'C1',\n",
       " 'C2',\n",
       " 'C3',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C6',\n",
       " 'C8',\n",
       " 'C9',\n",
       " 'C10',\n",
       " 'C11',\n",
       " 'C12',\n",
       " 'C13',\n",
       " 'C14',\n",
       " 'D1',\n",
       " 'D2',\n",
       " 'D3',\n",
       " 'D4',\n",
       " 'D5',\n",
       " 'D6',\n",
       " 'D8',\n",
       " 'D9',\n",
       " 'D10',\n",
       " 'D11',\n",
       " 'D12',\n",
       " 'D13',\n",
       " 'D14',\n",
       " 'D15',\n",
       " 'M2',\n",
       " 'M3',\n",
       " 'M4',\n",
       " 'M5',\n",
       " 'M6',\n",
       " 'M9',\n",
       " 'V2',\n",
       " 'V12',\n",
       " 'V13',\n",
       " 'V20',\n",
       " 'V25',\n",
       " 'V29',\n",
       " 'V30',\n",
       " 'V33',\n",
       " 'V35',\n",
       " 'V38',\n",
       " 'V43',\n",
       " 'V44',\n",
       " 'V45',\n",
       " 'V48',\n",
       " 'V49',\n",
       " 'V53',\n",
       " 'V54',\n",
       " 'V55',\n",
       " 'V56',\n",
       " 'V61',\n",
       " 'V62',\n",
       " 'V66',\n",
       " 'V67',\n",
       " 'V69',\n",
       " 'V70',\n",
       " 'V72',\n",
       " 'V73',\n",
       " 'V75',\n",
       " 'V76',\n",
       " 'V77',\n",
       " 'V78',\n",
       " 'V79',\n",
       " 'V81',\n",
       " 'V82',\n",
       " 'V83',\n",
       " 'V86',\n",
       " 'V87',\n",
       " 'V90',\n",
       " 'V91',\n",
       " 'V94',\n",
       " 'V96',\n",
       " 'V99',\n",
       " 'V102',\n",
       " 'V112',\n",
       " 'V115',\n",
       " 'V126',\n",
       " 'V128',\n",
       " 'V129',\n",
       " 'V130',\n",
       " 'V131',\n",
       " 'V133',\n",
       " 'V139',\n",
       " 'V140',\n",
       " 'V143',\n",
       " 'V149',\n",
       " 'V152',\n",
       " 'V156',\n",
       " 'V162',\n",
       " 'V164',\n",
       " 'V165',\n",
       " 'V169',\n",
       " 'V170',\n",
       " 'V182',\n",
       " 'V187',\n",
       " 'V188',\n",
       " 'V189',\n",
       " 'V198',\n",
       " 'V201',\n",
       " 'V205',\n",
       " 'V206',\n",
       " 'V208',\n",
       " 'V210',\n",
       " 'V212',\n",
       " 'V215',\n",
       " 'V216',\n",
       " 'V219',\n",
       " 'V220',\n",
       " 'V245',\n",
       " 'V251',\n",
       " 'V256',\n",
       " 'V257',\n",
       " 'V258',\n",
       " 'V261',\n",
       " 'V266',\n",
       " 'V272',\n",
       " 'V277',\n",
       " 'V278',\n",
       " 'V279',\n",
       " 'V280',\n",
       " 'V281',\n",
       " 'V283',\n",
       " 'V285',\n",
       " 'V288',\n",
       " 'V290',\n",
       " 'V291',\n",
       " 'V293',\n",
       " 'V294',\n",
       " 'V296',\n",
       " 'V300',\n",
       " 'V307',\n",
       " 'V308',\n",
       " 'V309',\n",
       " 'V310',\n",
       " 'V311',\n",
       " 'V312',\n",
       " 'V313',\n",
       " 'V314',\n",
       " 'V315',\n",
       " 'V316',\n",
       " 'V317',\n",
       " 'V318',\n",
       " 'V320',\n",
       " 'V326',\n",
       " 'V332',\n",
       " 'V333',\n",
       " 'V338',\n",
       " 'id_01',\n",
       " 'id_02',\n",
       " 'id_03',\n",
       " 'id_05',\n",
       " 'id_06',\n",
       " 'id_09',\n",
       " 'id_13',\n",
       " 'id_14',\n",
       " 'id_17',\n",
       " 'id_18',\n",
       " 'id_19',\n",
       " 'id_20',\n",
       " 'id_21',\n",
       " 'id_23',\n",
       " 'id_24',\n",
       " 'id_30',\n",
       " 'id_31',\n",
       " 'id_32',\n",
       " 'id_33',\n",
       " 'id_38',\n",
       " 'DeviceType',\n",
       " 'DeviceInfo',\n",
       " 'Transaction_hour',\n",
       " 'TransactionAmt_decimal',\n",
       " 'card1_freq',\n",
       " 'card2_freq',\n",
       " 'card3_freq',\n",
       " 'card4_freq',\n",
       " 'card5_freq',\n",
       " 'card4_card6',\n",
       " 'addr1_addr2_freq',\n",
       " 'P_emaildomain_knowngroups',\n",
       " 'R_emaildomain_knowngroups',\n",
       " 'P_emaildomain_net_com',\n",
       " 'R_emaildomain_net_com',\n",
       " 'M_true_count',\n",
       " 'deviceInfo_freq']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/rfe_features_200.pkl', 'rb') as f:\n",
    "    rfe_feature = pickle.load(f)\n",
    "features_columns = rfe_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = train_full[features_columns]\n",
    "# y = train_full['isFraud']\n",
    "\n",
    "# Split holdout as 15% of the train set\n",
    "X, X_holdout, y, y_holdout = train_test_split(train_full[features_columns], train_full['isFraud'], test_size=0.15, random_state=42)\n",
    "\n",
    "del train_full\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.05, # speed up the learning rate a bit - might sacrifice a bit of accuracy\n",
    "                    'num_leaves': 200, #2**8, # reduce number of leaves to reduce overfitting\n",
    "                    'max_depth': 8, # max_depth should be constrained, -1 would mean unconstrained\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.7,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.7,\n",
    "                    'n_estimators':10000,\n",
    "                    'max_bin':150, # less bins\n",
    "                    'verbose':-1,\n",
    "                    'seed': 2019,\n",
    "                    'early_stopping_rounds':100,\n",
    "#                     'lambda_l1':5,\n",
    "#                     'lambda_l2':5,\n",
    "                } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\martin.cheung\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:113: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\martin.cheung\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:118: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's auc: 0.968048\tvalid_1's auc: 0.945043\n",
      "[400]\ttraining's auc: 0.982622\tvalid_1's auc: 0.956434\n",
      "[600]\ttraining's auc: 0.991145\tvalid_1's auc: 0.962856\n",
      "[800]\ttraining's auc: 0.995823\tvalid_1's auc: 0.966854\n"
     ]
    }
   ],
   "source": [
    "NFOLDS =5\n",
    "folds = StratifiedKFold(n_splits=NFOLDS,random_state=123,shuffle=True) # split by stratified folds\n",
    "# folds = TimeSeriesSplit(n_splits=NFOLDS) # split by time\n",
    "\n",
    "aucs = []\n",
    "clfs=[]\n",
    "pred_len = len(test_full)\n",
    "prediction = np.zeros(pred_len)\n",
    "\n",
    "for fold, (trn_idx, test_idx) in enumerate(folds.split(X,y)):\n",
    "    print('Training on fold {}'.format(fold + 1))\n",
    "    \n",
    "    trn_data = lgb.Dataset(data=X.iloc[trn_idx], label=y.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(data=X.iloc[test_idx], label=y.iloc[test_idx])\n",
    "    clf = lgb.train(params, \n",
    "                    trn_data, \n",
    "                    valid_sets = [trn_data, val_data], \n",
    "                    verbose_eval=200)\n",
    "    \n",
    "    print('AUC for validation fold {}: {}'.format(fold+1, clf.best_score['valid_1']['auc']))\n",
    "    aucs.append(clf.best_score['valid_1']['auc'])\n",
    "    \n",
    "    holdout_pred = clf.predict(X_holdout)\n",
    "    print('AUC for holdout set - fold ', roc_auc_score(y_holdout, holdout_pred))\n",
    "    \n",
    "    prediction += clf.predict(test_full[features_columns])\n",
    "\n",
    "print(\"Cross Validation AUC: \", sum(aucs)/NFOLDS)\n",
    "final_predictions = prediction/NFOLDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average AUC for the timeseries split is much lower, and the LB score is a lower too. Might not be the correct CV scheme for time series as well. Still inconclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 20))\n",
    "lgb.plot_importance(clf,max_num_features=50,ax=ax)\n",
    "# for i in range(NFOLDS):\n",
    "#     fig, ax = plt.subplots(figsize=(15, 20))\n",
    "#     xgb.plot_importance(clfs[i],max_num_features=50,ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv', index_col='TransactionID')\n",
    "sample_submission['isFraud'] = prediction\n",
    "sample_submission.to_csv('data/lightgbm_CV_holdout.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
