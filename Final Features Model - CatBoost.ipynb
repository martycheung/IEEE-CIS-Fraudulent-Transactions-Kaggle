{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Features Model - CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import datetime\n",
    "import missingno as msno\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit, train_test_split,StratifiedKFold\n",
    "import gc\n",
    "from statistics import mean\n",
    "import pickle\n",
    "\n",
    "# import catboost\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Cross Validation\n",
    "1. Divide Train set in subsets (Training set itself + Local Test set)\n",
    "2. Define Validation Metric (in our case it is ROC-AUC)\n",
    "3. Stop training when Validation metric stops improving\n",
    "4. Take average of each fold's prediction for the Local Test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full = pd.read_pickle('data/train_feat.pkl')\n",
    "test_full = pd.read_pickle('data/test_feat.pkl')\n",
    "\n",
    "# # Not using the below since the object type is all converted to category type already\n",
    "# # Label Encoding for categoricals\n",
    "# for f in test_full.columns:\n",
    "#     if train_full[f].dtype=='object' or test_full[f].dtype=='object': \n",
    "#         train_full[f] = train_full[f].fillna('unseen_before_label')\n",
    "#         test_full[f]  = test_full[f].fillna('unseen_before_label')\n",
    "#         lbl = preprocessing.LabelEncoder()\n",
    "#         lbl.fit(list(train_full[f].values) + list(test_full[f].values))\n",
    "#         train_full[f] = lbl.transform(list(train_full[f].values))\n",
    "#         test_full[f] = lbl.transform(list(test_full[f].values)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/corr_feat.pkl', 'rb') as f:\n",
    "    correlated_features = pickle.load(f)\n",
    "    \n",
    "rm_cols = [\n",
    "    'TransactionID','TransactionDT', \n",
    "    'isFraud',\n",
    "    'id_31'  # remove time dependent features - these cause model to overfit too much\n",
    "#     'V300','V309','V111','V124','V106','V125','V315','V134','V102','V123','V316','V113',\n",
    "#               'V136','V305','V110','V299','V289','V286','V318','V304','V116','V284','V293',\n",
    "#               'V137','V295','V301','V104','V311','V115','V109','V119','V321','V114','V133','V122','V319',\n",
    "#               'V105','V112','V118','V117','V121','V108','V135','V320','V303','V297','V120',\n",
    "#               'V1','V14','V41','V65','V88', 'V89', 'V107', 'V68', 'V28', 'V27', 'V29', 'V241','V269',\n",
    "#               'V240', 'V325', 'V138', 'V154', 'V153', 'V330', 'V142', 'V195', 'V302', 'V328', 'V327', \n",
    "#               'V198', 'V196', 'V155' # remove bunch of V features\n",
    "] + correlated_features\n",
    "\n",
    "# Final features\n",
    "features_columns = [col for col in list(train_full.columns) if col not in rm_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = []\n",
    "for f in features_columns:\n",
    "    if train_full[f].dtype=='object' or test_full[f].dtype=='object':\n",
    "        cat_features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NA's for numerics\n",
    "train_full = train_full.fillna(-9999)\n",
    "test_full = test_full.fillna(-9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_full[features_columns]\n",
    "y = train_full['isFraud']\n",
    "\n",
    "# # Split holdout as 15% of the train set\n",
    "# X, X_holdout, y, y_holdout = train_test_split(train_full[features_columns], train_full['isFraud'], \n",
    "#                                               test_size=0.15, random_state=42, shuffle=False)\n",
    "# #                                               stratify = train_full['isFraud'])\n",
    "\n",
    "del train_full\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_params = {\n",
    "        'learning_rate': 0.2,\n",
    "        'bagging_temperature': 0.1, \n",
    "        'l2_leaf_reg': 30,\n",
    "        'depth': 12, \n",
    "#         'max_leaves': 48,\n",
    "        'max_bin':255,\n",
    "        'iterations' : 1000,\n",
    "        'loss_function' : \"Logloss\",\n",
    "        'objective':'CrossEntropy',\n",
    "        'eval_metric' : \"AUC\",\n",
    "#         'bootstrap_type' : 'Bayesian',\n",
    "        'random_seed':1337,\n",
    "        'early_stopping_rounds' : 100,\n",
    "        'use_best_model': True \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1\n"
     ]
    }
   ],
   "source": [
    "NFOLDS =5\n",
    "# folds = StratifiedKFold(n_splits=NFOLDS,random_state=123,shuffle=False) # split by stratified folds. Do shuffle =F\n",
    "folds = KFold(n_splits=NFOLDS,random_state=123,shuffle=False) # split by stratified folds\n",
    "# folds = TimeSeriesSplit(n_splits=NFOLDS) # split by time - try timeseries split, perhaps less overfitting? result: worse overfitting\n",
    "\n",
    "aucs = []\n",
    "clfs=[]\n",
    "pred_len = len(test_full)\n",
    "prediction = np.zeros(pred_len)\n",
    "\n",
    "for fold, (trn_idx, test_idx) in enumerate(folds.split(X,y)):\n",
    "    print('Training on fold {}'.format(fold + 1))\n",
    "    \n",
    "    clf = CatBoostClassifier(**cat_params)        \n",
    "    clf.fit(\n",
    "            X.iloc[trn_idx,:],y[trn_idx],\n",
    "            eval_set=(X.iloc[test_idx,:], y[test_idx]),\n",
    "            cat_features=cat_features,\n",
    "#             use_best_model=True,\n",
    "            verbose=True)\n",
    "    \n",
    "    \n",
    "    print('AUC for validation fold {}: {}'.format(fold+1, clf.get_best_score()))\n",
    "    aucs.append(clf.get_best_score())\n",
    "    \n",
    "#     holdout_pred = clf.predict(X_holdout)\n",
    "#     print('AUC for holdout set - fold ', roc_auc_score(y_holdout, holdout_pred))\n",
    "    \n",
    "    prediction += clf.predict(test_full[features_columns])\n",
    "\n",
    "print(\"Cross Validation AUC: \", sum(aucs)/NFOLDS)\n",
    "final_predictions = prediction/NFOLDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Catboost Model, final features -> CV: ; LB:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 20))\n",
    "xgb.plot_importance(clf,max_num_features=50,ax=ax,)\n",
    "# for i in range(NFOLDS):\n",
    "#     fig, ax = plt.subplots(figsize=(15, 20))\n",
    "#     xgb.plot_importance(clfs[i],max_num_features=50,ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv', index_col='TransactionID')\n",
    "sample_submission['isFraud'] = prediction\n",
    "sample_submission.to_csv('data/catboost_finalfeat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
