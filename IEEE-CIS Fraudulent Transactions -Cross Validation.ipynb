{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import datetime\n",
    "import missingno as msno\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit, train_test_split,StratifiedKFold\n",
    "import gc\n",
    "from statistics import mean\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Cross Validation\n",
    "1. Divide Train set in subsets (Training set itself + Local Test set)\n",
    "2. Define Validation Metric (in our case it is ROC-AUC)\n",
    "3. Stop training when Validation metric stops improving\n",
    "4. Take average of each fold's prediction for the Local Test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 650.48 Mb (66.6% reduction)\n",
      "Mem. usage decreased to 565.37 Mb (66.2% reduction)\n"
     ]
    }
   ],
   "source": [
    "train_full = pd.read_pickle('data/train_full.pkl')\n",
    "test_full = pd.read_pickle('data/test_full.pkl')\n",
    "\n",
    "train_full = train_full.fillna(-999)\n",
    "test_full = test_full.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "for f in test_full.columns:\n",
    "    if train_full[f].dtype=='object' or test_full[f].dtype=='object': \n",
    "        train_full[f] = train_full[f].fillna('unseen_before_label')\n",
    "        test_full[f]  = test_full[f].fillna('unseen_before_label')\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(train_full[f].values) + list(test_full[f].values))\n",
    "        train_full[f] = lbl.transform(list(train_full[f].values))\n",
    "        test_full[f] = lbl.transform(list(test_full[f].values)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_full.to_pickle('train_full_min.pkl')\n",
    "# test_full.to_pickle('test_full_min.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_cols = [\n",
    "    'TransactionID','TransactionDT', # These columns are pure noise right now\n",
    "    'isFraud',                          # Not target in features))\n",
    "    'DT_M'                           # Column that we used to simulate test set\n",
    "]\n",
    "\n",
    "# Final features\n",
    "features_columns = [col for col in list(train_full.columns) if col not in rm_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_full[features_columns]\n",
    "y = train_full['isFraud']\n",
    "\n",
    "X_test = xgb.DMatrix(test_full[features_columns])\n",
    "pred_len = len(test_full)\n",
    "del train_full,test_full\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { 'n_estimators':500,\n",
    "           'max_depth':9,\n",
    "           'learning_rate':0.05,\n",
    "           'subsample':0.9,\n",
    "           'colsample_bytree':0.9,\n",
    "           'missing':-999,\n",
    "           'random_state':2019,\n",
    "           'tree_method':'gpu_hist', #'gpu_exact', # THE MAGICAL PARAMETER\n",
    "           'eval_metric':'auc'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\martin.cheung\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.810665\tvalid-auc:0.808429\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-auc:0.987365\tvalid-auc:0.954668\n",
      "[2000]\ttrain-auc:0.996761\tvalid-auc:0.962394\n",
      "[3000]\ttrain-auc:0.999238\tvalid-auc:0.962218\n",
      "Stopping. Best iteration:\n",
      "[2504]\ttrain-auc:0.99835\tvalid-auc:0.963055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NFOLDS =5\n",
    "folds = StratifiedKFold(n_splits=NFOLDS,random_state=123,shuffle=True)\n",
    "\n",
    "aucs = []\n",
    "clfs=[]\n",
    "prediction = np.zeros(pred_len)\n",
    "\n",
    "for fold, (trn_idx, test_idx) in enumerate(folds.split(X, y)):\n",
    "    print('Training on fold {}'.format(fold + 1))\n",
    "    \n",
    "    trn_data = xgb.DMatrix(data=X.iloc[trn_idx], label=y.iloc[trn_idx])\n",
    "    val_data = xgb.DMatrix(data=X.iloc[test_idx], label=y.iloc[test_idx])\n",
    "    clf = xgb.train(params, trn_data, num_boost_round= 10000, evals = [(trn_data,'train'), (val_data,'valid')], verbose_eval=1000, early_stopping_rounds=500)\n",
    "    \n",
    "    print('AUC for fold {}: {}'.format(fold+1, clf.best_score))\n",
    "    \n",
    "    aucs.append(clf.best_score)\n",
    "#     clfs.append(clf)\n",
    "    \n",
    "    prediction += clf.predict(X_test)\n",
    "\n",
    "print(\"Cross Validation AUC: \", sum(aucs)/NFOLDS)\n",
    "final_predictions = prediction/NFOLDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 20))\n",
    "xgb.plot_importance(clfs[0],max_num_features=50,ax=ax)\n",
    "# for i in range(NFOLDS):\n",
    "#     fig, ax = plt.subplots(figsize=(15, 20))\n",
    "#     xgb.plot_importance(clfs[i],max_num_features=50,ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv', index_col='TransactionID')\n",
    "sample_submission['isFraud'] = prediction\n",
    "sample_submission.to_csv('data/xgboost_cv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "- build time of day/ week, month features (D9 is already a time of day feature, but because it has alot of NAs, better to create using the timedelta variable)\n",
    "- Hour and TransactionPerHour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Time dependent features\n",
    "# # https://www.kaggle.com/fchmiel/day-and-time-powerful-predictive-feature\n",
    "# train_full['Transaction_day_of_week'] = np.floor((train_full['TransactionDT'] / (3600 * 24) - 1) % 7)\n",
    "# test_full['Transaction_day_of_week'] = np.floor((test_full['TransactionDT'] / (3600 * 24) - 1) % 7)\n",
    "# train_full['Transaction_hour'] = np.floor(train_full['TransactionDT'] / 3600) % 24\n",
    "# test_full['Transaction_hour'] = np.floor(test_full['TransactionDT'] / 3600) % 24"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
